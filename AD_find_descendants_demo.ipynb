{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNOMED Files\n",
    "https://www.nlm.nih.gov/healthit/snomedct/international.html </br>\n",
    "This script uses 2024-03-01 version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sct2_Description_Snapshot-en_INT_20240301.txt: it containts SNOMED ID and the text description.\n",
    "# Example: 85828009 Autoimmune disease (disorder)\n",
    "delimiter = '\\t'\n",
    "\n",
    "file_path = os.getcwd() + '/SnomedCT_InternationalRF2_PRODUCTION_20240301T120000Z/Snapshot/Terminology/'\n",
    "file = file_path+'sct2_Description_Snapshot-en_INT_20240301.txt'\n",
    "df_description = pd.read_csv(file, delimiter=delimiter, on_bad_lines=\"warn\")\n",
    "print(df_description.shape)\n",
    "\n",
    "### sct2_Relationship_Snapshot_INT_20240301.txt: it contains the relationships between SNOMED IDs.\n",
    "file = file_path+'sct2_Relationship_Snapshot_INT_20240301.txt'\n",
    "df_relationship = pd.read_csv(file, delimiter=delimiter, on_bad_lines=\"warn\")\n",
    "print(df_relationship.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define IDs to be excluded/marked as excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if your project requires you to exclude certain IDs, we will first find all excluded IDs and their descendants\n",
    "\n",
    "def find_all_excluded_ids(start_ids, df):\n",
    "    # Initialize list to hold all descendants\n",
    "    all_descendants = []\n",
    "\n",
    "    # Process each starting ID in the list\n",
    "    for start_id in start_ids:\n",
    "        # Initialize queue and visited set for each start_id\n",
    "        queue = [start_id]\n",
    "        visited = set()\n",
    "\n",
    "        while queue:\n",
    "            current_id = queue.pop(0)\n",
    "\n",
    "            if current_id not in visited:\n",
    "                visited.add(current_id)\n",
    "                # Filter the DataFrame based on the given conditions\n",
    "                # active: means it is valid in the current version we are using\n",
    "                # typeId as 116680003: \"Is a (attribute)\", this indicates parent-child relationship\n",
    "                # https://browser.ihtsdotools.org/?perspective=full&conceptId1=116680003&edition=MAIN/2024-05-01&release=&languages=en&latestRedirect=false\n",
    "                condition = (df[\"destinationId\"] == current_id) & (df[\"active\"] == 1) & (df[\"typeId\"] == 116680003)\n",
    "                filtered_df = df[condition]\n",
    "                filtered_df = filtered_df.astype('int64')\n",
    "\n",
    "                # Collect all sourceIds which are the descendants of the current_id\n",
    "                current_descendants = filtered_df['sourceId'].tolist()\n",
    "                all_descendants.extend(current_descendants)\n",
    "\n",
    "                # Queue up the new descendants for further exploration\n",
    "                queue.extend(current_descendants)\n",
    "\n",
    "    # Remove duplicates from the list of all descendants\n",
    "    all_descendants = list(set(all_descendants))\n",
    "\n",
    "    return all_descendants\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find all descendants for the parent IDs we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find all descendants and store them in a dataframe; mark the IDs in excluded_ids\n",
    "# this output can be useful for healthcare providers to review if certain codes are missing or need to be validated. \n",
    "# Instead of directly removing the codes, we use the column \"Include Y/N\" to denote their suitability\n",
    "\n",
    "def find_all_descendants_df(start_id, df, excluded_ids=[]):\n",
    "    # Define IDs for special marking in the 'Include Y/N' column\n",
    "\n",
    "    # Initialize lists to hold results\n",
    "    ancestor_ids = []\n",
    "    candidate_ids = []\n",
    "    include_flags = []\n",
    "\n",
    "    # Start with the initial ancestor\n",
    "    queue = [(start_id, start_id in excluded_ids)]\n",
    "    visited = set()\n",
    "\n",
    "    while queue:\n",
    "        current_id, is_excluded_origin = queue.pop(0)\n",
    "        \n",
    "        if current_id not in visited:\n",
    "            visited.add(current_id)\n",
    "            # Filter the DataFrame based on the given conditions\n",
    "            condition = (df[\"destinationId\"] == current_id) & (df[\"active\"] == 1) & (df[\"typeId\"] == 116680003)\n",
    "            filtered_df = df[condition]\n",
    "            filtered_df = filtered_df.astype('int64')\n",
    "            \n",
    "            # Collect all sourceIds which are the descendants of the current_id\n",
    "            current_descendants = filtered_df['sourceId'].tolist()\n",
    "            for descendant in current_descendants:\n",
    "                # Add details to lists\n",
    "                ancestor_ids.append(start_id)\n",
    "                candidate_ids.append(int(descendant))\n",
    "                # If the current branch is from an excluded origin, mark descendant as 'N'\n",
    "                include_flags.append('N' if is_excluded_origin or descendant in excluded_ids else 'Y')\n",
    "                # Queue up the new descendants for further exploration\n",
    "                queue.append((descendant, is_excluded_origin or descendant in excluded_ids))\n",
    "\n",
    "    # Create a DataFrame for the results\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Ancestor SCTID\": ancestor_ids,\n",
    "        \"Candidate SCTID\": candidate_ids,\n",
    "        \"Include Y/N\": include_flags\n",
    "    })\n",
    "\n",
    "    results_df = results_df.drop_duplicates(subset=['Candidate SCTID'])\n",
    "    print(\"check the number of rows with 'Details' on SNOMED CT browser for SNOMED ID: %d\"%start_id)\n",
    "    print(results_df.shape) \n",
    "    # you can check the number of rows with \"Details\" on SNOMED CT browser\n",
    "    # Example: It shows \"Defined, Active. Descendants Count: 688 concepts.\" for Autoimmune disease (disorder)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the list of codes we want to exclude as they do not quality as autoimmune diseases\n",
    "excluded_id_0 = [778004006, 829973009, 1148765006, 78069008, 1197477000, \n",
    "                86081009, 1186652002, 723384004, 20005002, 426760008]\n",
    "\n",
    "excluded_ids = find_all_excluded_ids(excluded_id_0, df_relationship)\n",
    "print(len(excluded_ids))\n",
    "\n",
    "# add the parent IDs and now we will have a complete list of IDs that we will exclude/marked as excluded later\n",
    "excluded_ids.extend(excluded_id_0)\n",
    "print(len(excluded_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### in this project, we consider the following conditions\n",
    "### 1. Immune hypersensitivity disorder by mechanism (disorder) 427439005\n",
    "# including psoriasis, etc.\n",
    "# 426760008 (Delayed hypersensitivity disorder (disorder)) is excluded\n",
    "### 2. Autoinflammatory disease (disorder) 42111000175103\n",
    "### 3. Multiple sclerosis (disorder) 24700007\n",
    "### 4. Spondyloarthritis (disorder) 784332006\n",
    "### 5. Diabetes mellitus type 1 (disorder) 46635009\n",
    "### 6. Pyoderma gangrenosum (disorder) 74578003\n",
    "\n",
    "df_IDs = pd.DataFrame(columns=['Ancestor SCTID', 'Candidate SCTID', 'Include Y/N'])\n",
    "included_ids=[85828009, 427439005, 42111000175103, 24700007, 784332006, 46635009, 74578003] #, \n",
    "for i in included_ids:\n",
    "    df = find_all_descendants_df(i, df_relationship, excluded_ids)\n",
    "    df_IDs = pd.concat([df_IDs,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_IDs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding text description to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add text description of SNOME IDs\n",
    "condition = (df_description[\"typeId\"]==900000000000003001)\n",
    "df_ancestor = df_description[condition].reset_index(drop=True)\n",
    "df_ancestor = df_ancestor[[\"conceptId\", \"term\"]]\n",
    "df_ancestor = df_ancestor.rename(columns={\"conceptId\":\"Ancestor SCTID\", \"term\":\"Ancestor Text\"})\n",
    "df_ancestor.head()\n",
    "\n",
    "condition = (df_description[\"typeId\"]==900000000000003001)\n",
    "df_candidate = df_description[condition].reset_index(drop=True)\n",
    "df_candidate = df_candidate[[\"conceptId\", \"term\"]]\n",
    "df_candidate = df_candidate.rename(columns={\"conceptId\":\"Candidate SCTID\", \"term\":\"Candidate Text\"})\n",
    "df_candidate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_1 = df_IDs.merge(df_ancestor, on=\"Ancestor SCTID\", how=\"left\")\n",
    "display(df_all_1.head())\n",
    "print(df_all_1.shape)\n",
    "\n",
    "df_all_2 = df_all_1.merge(df_candidate, on=\"Candidate SCTID\", how=\"left\")\n",
    "display(df_all_2.head())\n",
    "print(df_all_2.shape)\n",
    "\n",
    "# df_all_2 may have more rows since sometimes there is more than one description for a SNOMED IDs. You can choose to keep all or drop duplicates and keep the first one.\n",
    "df_all_3 = df_all_2.drop_duplicates(subset=['Ancestor SCTID', 'Candidate SCTID'], keep='first')\n",
    "print(df_all_3.shape)\n",
    "\n",
    "# reorder columns\n",
    "cols = ['Ancestor SCTID', 'Ancestor Text', 'Candidate SCTID', 'Candidate Text', 'Include Y/N']\n",
    "df_all_4 = df_all_3[cols]\n",
    "display(df_all_4.head())\n",
    "print(df_all_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lastly, we will save the final dataframe to excel.\n",
    "\n",
    "# we first convert all values to string. This is important since saving integers to excel will sometimes make the numbers as scientific numbers, and the values will be off\n",
    "df_all_4 = df_all_4.astype(str)\n",
    "df_all_4.to_excel('AD_SNOMED_version_2024-03-01.xlsx', index=False, engine='openpyxl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
